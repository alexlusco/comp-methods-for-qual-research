---
title: "Computational Methods for Qualitative Research in Criminology and Criminal Justice Studies"
description: |
  Article supplement
author:
  - first_name: "Alex"
    last_name: "Luscombe"
    url: https://www.alexluscombe.ca
    affiliation: University of Toronto
    affiliation_url: 
    orcid_id: 0000-0002-3052-5401
  - first_name: "Jamie"
    last_name: "Duncan"
    url: https://jamieduncan.me/
    affiliation: University of Toronto
    affiliation_url: 
    orcid_id: 0000-0002-5456-6486
  - first_name: "Kevin"
    last_name: "Walby"
    url: https://www.uwinnipeg.ca/caij/about/index.html
    affiliation: University of Winnipeg
    affiliation_url: 
    orcid_id: 0000-0002-5107-2309
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_depth: 3
    code_folding: true
---

# Defining the Problem

# Collecting

### Website Recon

!()[images/scrape_diagram.png]

### Index Scrape

### Contents Scrape

# Parsing, Cleaning, and Exploring

```{r}
library(readr)
```

```{r}
rcmp_news <- read_csv(here::here("rcmp-news-final-df-preprocessed.csv"))
```

Let's take a look at the results our DataFrame so far. For this we can use the ```head``` function from base R to view only the first 6 rows (we don't need to inspect all 13,000 + at this stage).

```{r}
library(rmarkdown)

paged_table(head(rcmp_news))
```

To deal with the issues identified in our desired `province_territory` column, we can write a function that re-labels each of the entries we want to re-label...

```{r}
library(dplyr)
library(ggplot2)
library(stringr)
library(ggridges)
library(hrbrthemes)
```


```{r}
p1 <- rcmp_news %>%
  group_by(prov_terr) %>%
  count(name = "count") %>%
  ggplot(aes(x = reorder(prov_terr, count), y = count)) +
  geom_col(fill = "#ca1928", show.legend = FALSE) +
  theme_ipsum(grid="") +
  theme(axis.text.x = element_blank()) +
  geom_text(aes(label=scales::comma(count)), hjust=0, nudge_y=50) +
  expand_limits(y = c(0, 3400)) +
  coord_flip() +
  labs(x = "", y = "")

p1
```
```{r}
rcmp_news_count <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(date_published)) %>%
  group_by(prov_terr, date_published) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published))) %>%
  count(name = "count", .drop = TRUE)

rcmp_news_count <- rcmp_news_count %>%
  mutate(date_published = format(date_published, "%Y-%m")) %>%
  mutate(date_published = paste(date_published, "-01", sep = "")) %>%
  mutate(date_published = as.Date(date_published, "%Y-%m-%d"))

rcmp_news_count <- rcmp_news_count %>%
  group_by(date_published, prov_terr) %>%
  summarize(count = sum(count)) %>%
  mutate(total = sum(count)) %>%
  mutate(prop = count/total) %>%
  filter(date_published != "2016-12-01")

p2 <- rcmp_news_count %>%
  ggplot(aes(x = date_published, y = prop, fill = prov_terr)) +
  geom_col(position = "stack") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_date(breaks = as.Date(c("2017-01-01", "2018-01-01", "2019-01-01", "2020-01-01")), date_labels = "%Y") +
  fishualize::scale_fill_fish_d() +
  theme_ipsum(grid = "") +
  labs(y = "Proportion", x = "",
       fill = "")

p2
```

```{r}
p3 <- rcmp_news_count %>%
  ggplot(aes(x = date_published, y = count, color = prov_terr)) +
  geom_smooth(se = FALSE) +
  scale_y_continuous() +
  scale_x_date(breaks = as.Date(c("2017-01-01", "2018-01-01", "2019-01-01", "2020-01-01")), date_labels = "%Y") +
  fishualize::scale_color_fish_d() +
  theme_ipsum(grid = "") +
  labs(y = "Number of news releases", x = "",
       color = "")

p3
```

```{r}
p4 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  mutate(word_count = str_count(full_text, "\\w+")) %>%
  mutate(word_count_mean = mean(word_count, na.rm = TRUE)) %>%
  group_by(prov_terr) %>%
  ggplot(aes(x = word_count, y = prov_terr)) +
  geom_density_ridges(fill = "#ca1928", show.legend = FALSE) +
  geom_vline(aes(xintercept = word_count_mean), linetype="dotted", size = 1) +
  scale_x_log10(breaks = c(1, 10, 100, 1000, 5805)) +
  theme_ipsum(grid = "X") +
  labs(x = "word count (log scale)", y = "")

p4
```

```{r, fig.width=13, fig.height=8}
library(cowplot)

plot_grid(labels = "AUTO", p1, p2, p3, p4)
```

# Sampling and Outputting

```{r}
library(gt)
library(paletteer)
library(tidyr)
```

```{r}
my_pattern <- "drug|contraband|bath salts|benzodiazepine|methamphetamine|ghb|cocaine|crack|cannabis|marijuana|weed|pot|hash|hashish|lsd| mdma|ecstasy|fentanyl|opioid|pcp|angel dust|acid|salvia|mushroom|heroin|ketamine"
```

```{r}
table1 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url),
         !is.na(full_text)) %>%
  group_by(prov_terr, image_url) %>%
  mutate(full_text = str_to_lower(full_text)) %>%
  count(tf = str_detect(full_text, my_pattern)) %>%
  group_by(prov_terr, tf) %>%
  summarize(sum = sum(n)) %>%
  pivot_wider(names_from = tf, values_from = sum) %>%
  mutate(`FALSE` = `FALSE` + `TRUE`) %>%
  rename(`Total NRs w/ Images 2` = `TRUE`,
         `Total NRs 2` = `FALSE`,
         `Province/Territory` = prov_terr) %>%
  mutate(`Percent NRs w/ Images 2` = round(`Total NRs w/ Images 2`/`Total NRs 2`*100, 2)) %>%
  ungroup()

table2 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  group_by(prov_terr) %>%
  add_count(prov_terr, name = "total_press_releases") %>%
  add_count(image_url, name = "total_images") %>%
  summarize(total_press_releases = max(total_press_releases),
            total_images = max(total_images)) %>%
  mutate(proportion = round(total_images/total_press_releases*100, 2)) %>%
  select(prov_terr, total_press_releases, total_images, proportion) %>%
  #arrange(desc(total_images)) %>%
  rename(`Province/Territory` = prov_terr,
         `Total NRs` = total_press_releases,
         `Total NRs w/ Images` = total_images,
         `Percent NRs w/ Images` = proportion) %>%
  ungroup()

table3 <- table2 %>%
  left_join(table1, by = c("Province/Territory" = "Province/Territory")) %>%
  rename(` ` = "Province/Territory")

table3 %>%
  gt() %>%
  tab_spanner(label = "Whole Corpus",
              columns = c(`Total NRs`, `Total NRs w/ Images`, `Percent NRs w/ Images`)) %>%
  tab_spanner(label = "Subset Corpus",
              columns = c(`Total NRs 2`, `Total NRs w/ Images 2`, `Percent NRs w/ Images 2`)) %>%
  data_color(
    columns = c(`Total NRs`, `Total NRs w/ Images`, `Percent NRs w/ Images`, `Total NRs 2`, `Total NRs w/ Images 2`, `Percent NRs w/ Images 2`),
    colors = scales::col_numeric(
      paletteer::paletteer_d(
        palette = "ggsci::red_material")
        %>% as.character(),
      domain = NULL
      )
  )
```

```{r, eval=FALSE}
image_meta_data <- rcmp_news %>% 
  ungroup() %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url)) %>%
  mutate(full_text = str_to_lower(full_text)) %>%
  filter(str_detect(full_text, my_pattern)) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published)))

image_urls <- image_meta_data %>% select(image_url)

image_urls1 <- slice(image_urls, 1:250)
image_meta_data1 <- slice(image_meta_data, 1:250)

image_urls2 <- slice(image_urls, 251:500)
image_meta_data2 <- slice(image_meta_data, 251:500)

image_urls3 <- slice(image_urls, 501:750)
image_meta_data3 <- slice(image_meta_data, 501:750)

image_urls4 <- slice(image_urls, 751:997)
image_meta_data4 <- slice(image_meta_data, 751:997)
```

```{r, eval=FALSE}
options(timeout=500)

for (i in image_urls1){
  
  numbers <- 1:250
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data1$prov_terr, "_RCMP_", image_meta_data1$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls2){
  
  numbers <- 251:500
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data2$prov_terr, "_RCMP_", image_meta_data2$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls3){
  
  numbers <- 501:750
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data3$prov_terr, "_RCMP_", image_meta_data3$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls4){
  
  numbers <- 751:997
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data4$prov_terr, "_RCMP_", image_meta_data4$date_published, "_", numbers, ".jpg", sep = ""))
}
```

```{r, eval=FALSE}
subset_corpus <- rcmp_news %>% 
  ungroup() %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url)) %>%
  mutate(full_text_lower = str_to_lower(full_text)) %>%
  filter(str_detect(full_text_lower, my_pattern)) %>%
  select(-full_text_lower, -region2) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published))) %>%
  mutate(doc_id = row_number())

subset_corpus <- subset_corpus %>%
  mutate(date_published2 = paste("\n\nDATE: ", as.character(date_published), "\n\n", sep = "")) %>%
  mutate(headline_text = paste("HEADLINE: ", headline_text, "\n\n", sep = "")) %>%
  mutate(headline_url = paste("ARTICLE URL: ", headline_url, "\n\n", sep = "")) %>%
  mutate(image_url = paste("IMAGE URL: ", image_url, "\n\n", sep = "")) %>%
  mutate(prov_terr2 = paste("CITY/TOWN, PROVINCE/TERRITORY: ", region1, prov_terr, "\n\n", sep = "")) %>%
  mutate(full_text = paste("FULL TEXT: ", full_text, "\n\n", sep = "")) %>%
  mutate(text = paste(date_published2, headline_text, headline_url, image_url, prov_terr2, full_text)) %>%
  mutate(doc_names = paste(prov_terr, "_RCMP_", date_published, "_", doc_id, sep = ""))

subset_corpus %>%
  select(doc_names, text) %>%
  group_by(doc_names) %>%
  do(write_csv(., paste0(unique(.$doc_names), ".txt", sep = ""), col_names = FALSE))
```

# Analyzing

# Findings, Discussion, and Conclusion