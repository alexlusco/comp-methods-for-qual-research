---
title: "Computational Methods for Qualitative Research in Criminology and Criminal Justice Studies"
description: |
  This article supplement, intended as a pedagogical tool, provides all of the code necessary to reproduce the case study illustration in *Computational Methods for Qualitative Research in Criminology and Criminal Justice Studies* (work in progress). To boost the pedagogical value of this resource, we have provided detailed explanations and commentaries throughout each step.
author:
  - first_name: "Alex"
    last_name: "Luscombe"
    url: https://www.alexluscombe.ca
    affiliation: University of Toronto
    affiliation_url: 
    orcid_id: 0000-0002-3052-5401
  - first_name: "Jamie"
    last_name: "Duncan"
    url: https://jamieduncan.me/
    affiliation: University of Toronto
    affiliation_url: 
    orcid_id: 0000-0002-5456-6486
  - first_name: "Kevin"
    last_name: "Walby"
    url: https://www.uwinnipeg.ca/caij/about/index.html
    affiliation: University of Winnipeg
    affiliation_url: 
    orcid_id: 0000-0002-5107-2309
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: false
---

# Defining the Problem

# Collecting

### Website Recon

![](images/scrape_diagram.png)

### Index Scrape

### Contents Scrape

# Parsing, Cleaning, and Exploring

```{r}
#install.packages("readr")
library(readr)

rcmp_news <- read_csv(here::here("rcmp-news-df.csv"))
```

Let's take a look at the results our DataFrame so far. For this we can use the `head()` function from base R to view only the first 6 rows of each variable.

```{r}
#install.packageS("rmarkdown")
library(rmarkdown)

paged_table(head(rcmp_news))
```

Inspecting the **region** variable, we can see that both the city/town/county and province/territory are grouped together and separated by a ",". For example, on the first row, we have "Iqaluit, Nunavut", and one the second row, we have "Dauphin, Manitoba". As it is going to be useful for our analysis to explore pattern in the data by province/territory, we will want to split the **region** variable so that we have two variables instead, one that contains the town/city/county information, and one that contains the province/territory information. We can achieve this using `separate()` function, which comes from library(tidyr). We will apply the `separate()` function to our region variable, saving the results of our DataFrame (rcmp_news) into a new DataFrame (rcmp_news_pp, where pp stands for "pre-processed"). The `separate()` function requires you to provide the names of the new variables you'll be creating (i.e., what the information on the left and right of the "," will be saved into). We will call these "region1" (town/city/county) and "region2" (province/territory).

```{r}
#install.packages("tidyr")
library(tidyr)

rcmp_news_pp <- rcmp_news %>%
  separate(region, c("region1", "region2"), sep = ", ")

paged_table(head(rcmp_news_pp, n = 200)) #inspect the results, again using the head() function, but this time let's inspect the first 200 results
```
Inspecting the first 200 results, we see that it *mostly* worked, until about page 14. On the second row of page 14, in the **region2** column, we can see that "Ontario Media advisory" has been entered where we expected the result to be just "Ontario". Flipping through more of the pages, we see a similar labeling issue on page 18 ("Ontario NCR", "Guysborough County") and on page 19 ("Manitoba Statement"). At this stage we should ask: how many of the **region2** values contain information other than just the name of the province/territory? The easiest way to do this is to use the `count()` function from library(dplyr) to count the total number of times that each unique entry appears in the **region2** variable. From here we can print the results of our count in a table that we can manually inspect.

```{r}
#install.packges("dplyr")
library(dplyr)

rcmp_region_count <- rcmp_news_pp %>%
  count(region2)
  
paged_table(rcmp_region_count)
```
Paging through the elements in this table, we can see two problems: 1) there's a lot of entries in the region2 variable that contain more or different information then the name of the province/territory; and 2) on the last page of the table, page 14, we see that there are 24 news releases in our corpus where the **region2** value is *NA*, meaning it is missing. This brings us to our first major cleaning operation: fixing the entries in our **region2** variable so that it only contains information on the province/territory of the RCMP detachment authoring the news release. To deal with this issue, we can write a custom function that re-labels each of the entries we want to re-label in region2. This is not the fastest nor most efficient way to achieve this result, but it is one of the easiest. (As this is a long chunk of code, we have hidden it from view. Click "Show code" to view.)

```{r code_folding=TRUE}
recode_regions <- function(region) {
  case_when(
    region %in% c(
      "Ontario National",
      "Ontario Statement",
      "Ontario Media advisory",
      "Ontario NCR",
      "Ontario National Statement",
      "Ontario National Media advisory",
      "Ontario National NCR",
      "Ontario National Statement NCR",
      "Ontario National Speech",
      "Ontario Statement NCR",
      "Ontario Speech",
      "Ontario Media advisory NCR"
    ) ~ "Ontario",
    region %in% c(
      "Manitoba Statement",
      "Saskatchewan National Speech",
      "Saskatchewan National Depot",
      "Saskatchewan Statement Depot",
      "Saskatchewan Media advisory",
      "Saskatchewan Depot",
      "Saskatchewan Media advisory Depot",
      "Saskatchewan National",
      "Saskatchewan National Statement",
      "Maidstone",
      "Shaunavon",
      "Saskatchewan Statement",
      "Archerwill",
      "Lake Diefenbaker",
      "Pelican Narrows",
      "Moose Jaw",
      "Weyburn",
      "Southend",
      "Emma Lake",
      "Biggar",
      "Langenburg"
    ) ~ "Saskatchewan",
    region %in% c(
      "Quebec National Media advisory",
      "Quebec National",
      "Quebec Media advisory"
    ) ~ "Quebec",
    region %in% c(
      "Nova Scotia Media advisory",
      "Nova Scotia National",
      "Halifax Regional Municipality",
      "Nova Scotia Speech",
      "Nova Scotia Statement",
      "Nova Scotia National Speech",
      "Queens and Kings Counties",
      "Victoria County",
      "Digby County",
      "Hants County",
      "Kings County",
      "Kings and Prince Counties",
      "Annapolis County",
      "Colchester County",
      "Antigonish County",
      "Queens and King counties",
      "Inverness County",
      "Queens County",
      "Lunenburg County",
      "Yarmouth County",
      "Antigonish County",
      "Hanty County",
      "Cumberland County",
      "Shelburne County",
      "Richmond County",
      "Green Creek",
      "Coichester County",
      "Richmond Co.",
      "Guysborough County",
      "Pictou County",
      "Annapolis COunty",
      "Annapolis Valley",
      "Hants Co."
    ) ~ "Nova Scotia",
    region %in% c(
      "Manitoba Statement",
      "Manitoba National",
      "Manitoba ",
      "Manitoba Media advisory",
      "Rosebank"
    ) ~ "Manitoba",
    region %in% c(
      "PEI",
      "Queens and Kings Districts",
      "Queens and Kings counties",
      "Queens and Kings County"
    ) ~ "Prince Edward Island",
    region %in% c(
      "N.B. ",
      "N.B.",
      "New Brunswick Statement",
      "Aroostook and Oxbow",
      "New Brunswick Media advisory",
      "NB"
    ) ~ "New Brunswick",
    region %in% c(
      "Yukon Media advisory",
      "Carcross",
      "Yukon ",
      "Whitehorse",
      "Yukon Statement",
      "Ross River",
      "Haines Junction",
      "Faro"
    ) ~ "Yukon",
    region %in% c(
      "Alberta Statement",
      "Alberta National",
      "Alberta Media advisory",
      "Alta.",
      "Alta",
      "Alberta Depot",
      "Alberta National Depot",
      "Alberta National Statement",
      "Three Hills and Stettler"
    ) ~ "Alberta",
    region %in% c(
      "Newfoundland and Labrador Media advisory",
      "Newfoundland and Labrador Statement",
      "Nain",
      "Stephenville",
      "Deer Lake",
      "Hopedale",
      "Ferryland and Stephenville",
      "Grand Falls-Windsor",
      "Holyrood and Stephenville"
    ) ~ "Newfoundland and Labrador",
    region %in% c(
      "British Columbia National",
      "Green Lake"
    ) ~ "British Columbia",
    region %in% c(
      "Nunavut Media advisory"
    ) ~ "Nunavut",
    region %in% c(
      "Northwest Territories Media advisory"
    ) ~ "Northwest Territories",
    TRUE ~ region
  )
}
```

Next we will apply our cleaning function to to our DataFrame, using the `mutate()` function from library(dplyr). Before this, to deal with the 24 *NA* values we identified in **region2**, we are going to apply another dplyr function called `coalesce()`, which will move replace the *NA* values in region2 with the values from **region1**. We also going to add one additional step before applying our custom cleaning function. This will be to trim any unnecessary white space from the beginning and end of each entry in **region2**. To do this, we use the `str_trim()` function from library(stringr). Next, we'll apply our cleaning function, after which we'll inspect the results to see if it worked.

```{r}
#install.packages("stringr")
library(stringr)

rcmp_news_pp <- rcmp_news_pp %>%
  mutate(region2 = coalesce(region2, region1)) %>%
  mutate(region2 = str_trim(region2)) %>%
  mutate(region2 = recode_regions(region2))

rcmp_region_count <- rcmp_news_pp %>%
  count(region2)
  
paged_table(rcmp_region_count)
```

It worked! Finally, let's rename our **region1** and **region2** variables, calling them **town_city_county** and **prov_terr**. To this we can use the `rename()` function from library(dplyr).

```{r}
rcmp_news_pp <- rcmp_news_pp %>%
  rename(town_city_county = region1,
         prov_terr = region2)
```

Now that we've fixed our issues with the province/territory data in our DataFrame, we can begin to explore the corpus. A great technique for getting to know the data in your corpus is to use *data visualization*. Combining standard data manipulation and data visualization techniques like counting and bar graphs, we can easily visualize some of the more macro-level patterns in our corpus (publication of news releases over time, by province/territory, etc.). To do this, we'll be using an R data visualization library called library(ggplot2). Since data often needs to be manipulated to some degree before visualization (e.g., counting the number of unique provinces/territories in the DataFrame, in order to create a bar chart visually representing the differences), we'll also be using more of library(stringr) and library(dplyr). Let's begin with a bar graph showing the total number of press releases in our corpus by province/territory. Note that to produce these graphs, we are going to use the theme aesthetics from library(hrbrthemes) and the default colour palette from library(fishualize), so you'll need to install these two libraries first before you can run the code.

```{r}
#install.packages("ggplot2")
#install.packages("hrbrthemes")
#install.packages("fishualize")
library(ggplot2)

rcmp_news_pp %>%
  group_by(prov_terr) %>%
  count(name = "count") %>%
  ggplot(aes(x = reorder(prov_terr, count), y = count)) +
  geom_col(fill = "#ca1928", show.legend = FALSE) +
  hrbrthemes::theme_ipsum(grid="") +
  theme(axis.text.x = element_blank()) +
  geom_text(aes(label=scales::comma(count)), hjust=0, nudge_y=50) +
  expand_limits(y = c(0, 3400)) +
  coord_flip() +
  labs(x = "", y = "")
```

Nova Scotia, New Brunswick, and Newfound and Labrador account for the majority of news releases in the database we scraped. The two largest provinces in Canada - Ontario and Quebec - account for the least. Why? Here we can use some domain knowledge to interpret this: There are very few RCMP detachments in Ontario and Quebec, as both have provincial police forces (Ontario Provincial Police and Sûreté du Québec) that absorb many of the police duties that would otherwise be contracted to the RCMP. This fits clearly with what we know about policing in Canada. What is less immediately clear is why British Columbia only has two entries. Based again on our domain knowledge, we know that British Columbia has a strong RCMP presence (and unlike Ontario and Québec, does not have a provincial police force to act in lieu of the RCMP). So why the low number of news releases? ...

Next, let's look at the total proportion of news releases produced over time by province/territory. To calculate this, we are going to manipulate the date variable, removing information about day and time, in order to count the total number of news releases produced by each province/territory for each year-month combination (2016-05, 2016-06, 2016-07, etc.).

```{r}
rcmp_news_count <- rcmp_news_pp %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(date_published)) %>%
  group_by(prov_terr, date_published) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published))) %>%
  count(name = "count", .drop = TRUE)

rcmp_news_count <- rcmp_news_count %>%
  mutate(date_published = format(date_published, "%Y-%m")) %>%
  mutate(date_published = paste(date_published, "-01", sep = "")) %>%
  mutate(date_published = as.Date(date_published, "%Y-%m-%d"))

rcmp_news_count <- rcmp_news_count %>%
  group_by(date_published, prov_terr) %>%
  summarize(count = sum(count)) %>%
  mutate(total = sum(count)) %>%
  mutate(prop = count/total) %>%
  filter(date_published != "2016-12-01")

rcmp_news_count %>%
  ggplot(aes(x = date_published, y = prop, fill = prov_terr)) +
  geom_col(position = "stack") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_date(breaks = as.Date(c("2017-01-01", "2018-01-01", "2019-01-01", "2020-01-01")), date_labels = "%Y") +
  fishualize::scale_fill_fish_d() +
  hrbrthemes::theme_ipsum(grid = "") +
  labs(y = "Proportion", x = "",
       fill = "")
```

Now let's do the same thing with the raw count rather than the proportion.

```{r}
rcmp_news_count %>%
  ggplot(aes(x = date_published, y = count, color = prov_terr)) +
  geom_smooth(se = FALSE) +
  scale_y_continuous() +
  scale_x_date(breaks = as.Date(c("2017-01-01", "2018-01-01", "2019-01-01", "2020-01-01")), date_labels = "%Y") +
  fishualize::scale_color_fish_d() +
  hrbrthemes::theme_ipsum(grid = "") +
  labs(y = "Number of news releases", x = "",
       color = "")
```

Finally, let's look at the distribution of total word count across each of the news releases in our corpus, again by province/territory. To produce this particular graph, we are going to use the `geom_density_ridges()` function from library(ggridges), an add on to library(ggplot2).

```{r}
#install.packages("ggridges")
library(ggridges)

rcmp_news_pp %>%
  filter(prov_terr != "British Columbia") %>%
  mutate(word_count = str_count(full_text, "\\w+")) %>%
  mutate(word_count_mean = mean(word_count, na.rm = TRUE)) %>%
  group_by(prov_terr) %>%
  ggplot(aes(x = word_count, y = prov_terr)) +
  geom_density_ridges(fill = "#ca1928", show.legend = FALSE) +
  geom_vline(aes(xintercept = word_count_mean), linetype="dotted", size = 1) +
  scale_x_log10(breaks = c(1, 10, 100, 1000, 5805)) +
  hrbrthemes::theme_ipsum(grid = "X") +
  labs(x = "word count (log scale)", y = "")
```

# Sampling and Outputting

```{r, eval=FALSE}
library(gt)
library(paletteer)
library(tidyr)
```

```{r, eval=FALSE}
my_pattern <- "drug|contraband|bath salts|benzodiazepine|methamphetamine|ghb|cocaine|crack|cannabis|marijuana|weed|pot|hash|hashish|lsd| mdma|ecstasy|fentanyl|opioid|pcp|angel dust|acid|salvia|mushroom|heroin|ketamine"
```

```{r, eval=FALSE}
table1 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url),
         !is.na(full_text)) %>%
  group_by(prov_terr, image_url) %>%
  mutate(full_text = str_to_lower(full_text)) %>%
  count(tf = str_detect(full_text, my_pattern)) %>%
  group_by(prov_terr, tf) %>%
  summarize(sum = sum(n)) %>%
  pivot_wider(names_from = tf, values_from = sum) %>%
  mutate(`FALSE` = `FALSE` + `TRUE`) %>%
  rename(`Total NRs w/ Images 2` = `TRUE`,
         `Total NRs 2` = `FALSE`,
         `Province/Territory` = prov_terr) %>%
  mutate(`Percent NRs w/ Images 2` = round(`Total NRs w/ Images 2`/`Total NRs 2`*100, 2)) %>%
  ungroup()

table2 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  group_by(prov_terr) %>%
  add_count(prov_terr, name = "total_press_releases") %>%
  add_count(image_url, name = "total_images") %>%
  summarize(total_press_releases = max(total_press_releases),
            total_images = max(total_images)) %>%
  mutate(proportion = round(total_images/total_press_releases*100, 2)) %>%
  select(prov_terr, total_press_releases, total_images, proportion) %>%
  #arrange(desc(total_images)) %>%
  rename(`Province/Territory` = prov_terr,
         `Total NRs` = total_press_releases,
         `Total NRs w/ Images` = total_images,
         `Percent NRs w/ Images` = proportion) %>%
  ungroup()

table3 <- table2 %>%
  left_join(table1, by = c("Province/Territory" = "Province/Territory")) %>%
  rename(` ` = "Province/Territory")

table3 %>%
  gt() %>%
  tab_spanner(label = "Whole Corpus",
              columns = c(`Total NRs`, `Total NRs w/ Images`, `Percent NRs w/ Images`)) %>%
  tab_spanner(label = "Subset Corpus",
              columns = c(`Total NRs 2`, `Total NRs w/ Images 2`, `Percent NRs w/ Images 2`)) %>%
  data_color(
    columns = c(`Total NRs`, `Total NRs w/ Images`, `Percent NRs w/ Images`, `Total NRs 2`, `Total NRs w/ Images 2`, `Percent NRs w/ Images 2`),
    colors = scales::col_numeric(
      paletteer::paletteer_d(
        palette = "ggsci::red_material")
        %>% as.character(),
      domain = NULL
      )
  )
```

```{r, eval=FALSE}
image_meta_data <- rcmp_news %>% 
  ungroup() %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url)) %>%
  mutate(full_text = str_to_lower(full_text)) %>%
  filter(str_detect(full_text, my_pattern)) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published)))

image_urls <- image_meta_data %>% select(image_url)

image_urls1 <- slice(image_urls, 1:250)
image_meta_data1 <- slice(image_meta_data, 1:250)

image_urls2 <- slice(image_urls, 251:500)
image_meta_data2 <- slice(image_meta_data, 251:500)

image_urls3 <- slice(image_urls, 501:750)
image_meta_data3 <- slice(image_meta_data, 501:750)

image_urls4 <- slice(image_urls, 751:997)
image_meta_data4 <- slice(image_meta_data, 751:997)
```

```{r, eval=FALSE}
options(timeout=500)

for (i in image_urls1){
  
  numbers <- 1:250
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data1$prov_terr, "_RCMP_", image_meta_data1$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls2){
  
  numbers <- 251:500
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data2$prov_terr, "_RCMP_", image_meta_data2$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls3){
  
  numbers <- 501:750
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data3$prov_terr, "_RCMP_", image_meta_data3$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls4){
  
  numbers <- 751:997
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data4$prov_terr, "_RCMP_", image_meta_data4$date_published, "_", numbers, ".jpg", sep = ""))
}
```

```{r, eval=FALSE}
subset_corpus <- rcmp_news %>% 
  ungroup() %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url)) %>%
  mutate(full_text_lower = str_to_lower(full_text)) %>%
  filter(str_detect(full_text_lower, my_pattern)) %>%
  select(-full_text_lower, -region2) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published))) %>%
  mutate(doc_id = row_number())

subset_corpus <- subset_corpus %>%
  mutate(date_published2 = paste("\n\nDATE: ", as.character(date_published), "\n\n", sep = "")) %>%
  mutate(headline_text = paste("HEADLINE: ", headline_text, "\n\n", sep = "")) %>%
  mutate(headline_url = paste("ARTICLE URL: ", headline_url, "\n\n", sep = "")) %>%
  mutate(image_url = paste("IMAGE URL: ", image_url, "\n\n", sep = "")) %>%
  mutate(prov_terr2 = paste("CITY/TOWN, PROVINCE/TERRITORY: ", region1, prov_terr, "\n\n", sep = "")) %>%
  mutate(full_text = paste("FULL TEXT: ", full_text, "\n\n", sep = "")) %>%
  mutate(text = paste(date_published2, headline_text, headline_url, image_url, prov_terr2, full_text)) %>%
  mutate(doc_names = paste(prov_terr, "_RCMP_", date_published, "_", doc_id, sep = ""))

subset_corpus %>%
  select(doc_names, text) %>%
  group_by(doc_names) %>%
  do(write_csv(., paste0(unique(.$doc_names), ".txt", sep = ""), col_names = FALSE))
```

# Analyzing

# Findings, Discussion, and Conclusion