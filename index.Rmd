---
title: "Computational Methods for Qualitative Research in Criminology and Criminal Justice Studies"
description: |
  Article supplement
author:
  - first_name: "Alex"
    last_name: "Luscombe"
    url: https://www.alexluscombe.ca
    affiliation: University of Toronto
    affiliation_url: 
    orcid_id: 0000-0002-3052-5401
  - first_name: "Jamie"
    last_name: "Duncan"
    url: https://jamieduncan.me/
    affiliation: University of Toronto
    affiliation_url: 
    orcid_id: 0000-0002-5456-6486
  - first_name: "Kevin"
    last_name: "Walby"
    url: https://www.uwinnipeg.ca/caij/about/index.html
    affiliation: University of Winnipeg
    affiliation_url: 
    orcid_id: 0000-0002-5107-2309
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: false
---

# Defining the Problem

# Collecting

### Website Recon

![](images/scrape_diagram.png)

### Index Scrape

### Contents Scrape

# Parsing, Cleaning, and Exploring

```{r}
#install.packages("readr")
library(readr)

rcmp_news <- read_csv(here::here("rcmp-news-df.csv"))
```

Let's take a look at the results our DataFrame so far. For this we can use the `head()` function from base R to view only the first 6 rows of each variable.

```{r}
#install.packageS("rmarkdown")
library(rmarkdown)

paged_table(head(rcmp_news))
```

Inspecting the **region** variable, we can see that both the city/town/county and province/territory are grouped together and separated by a ",". For example, on the first row, we have "Iqaluit, Nunavut", and one the second row, we have "Dauphin, Manitoba". As it is going to be useful for our analysis to explore pattern in the data by province/territory, we will want to split the **region** variable so that we have two variables instead, one that contains the town/city/county information, and one that contains the province/territory information. We can achieve this using `separate()` function, which comes from library(tidyr). We will apply the `separate()` function to our region variable, saving the results of our DataFrame (rcmp_news) into a new DataFrame (rcmp_news_pp, where pp stands for "pre-processed"). The `separate()` function requires you to provide the names of the new variables you'll be creating (i.e., what the information on the left and right of the "," will be saved into). We will call these "region1" (town/city/county) and "region2" (province/territory).

```{r}
#install.packages("tidyr")
library(tidyr)

rcmp_news_pp <- rcmp_news %>%
  separate(region, c("region1", "region2"), sep = ", ")

paged_table(head(rcmp_news_pp, n = 200)) #inspect the results, again using the head() function, but this time let's inspect the first 200 results
```
Inspecting the first 200 results, we see that it *mostly* worked, until about page 14. On the second row of page 14, in the **region2** column, we can see that "Ontario Media advisory" has been entered where we expected the result to be just "Ontario". Flipping through more of the pages, we see a similar labeling issue on page 18 ("Ontario NCR", "Guysborough County") and on page 19 ("Manitoba Statement"). At this stage we should ask: how many of the **region2** values contain information other than just the name of the province/territory? The easiest way to do this is to use the `count()` function from library(dplyr) to count the total number of times that each unique entry appears in the **region2** variable. From here we can print the results of our count in a table that we can manually inspect.

```{r}
#install.packges("dplyr")
library(dplyr)

rcmp_region_count <- rcmp_news_pp %>%
  count(region2)
  
paged_table(rcmp_region_count)
```
Paging through the elements in this table, we can see two problems: 1) there's a lot of entries in the region2 variable that contain more or different information then the name of the province/territory; and 2) on the last page of the table, page 14, we see that there are 24 news releases in our corpus where the **region2** value is *NA*, meaning it is missing. This brings us to our first major cleaning operation: fixing the entries in our **region2** variable so that it only contains information on the province/territory of the RCMP detachment authoring the news release. To deal with this issue, we can write a custom function that re-labels each of the entries we want to re-label in region2. This is not the fastest nor most efficient way to achieve this result, but it is one of the easiest. (As this is a long chunk of code, we have hidden it from view. Click "Show code" to view.)

```{r code_folding=TRUE}
recode_regions <- function(region) {
  case_when(
    region %in% c(
      "Ontario National",
      "Ontario Statement",
      "Ontario Media advisory",
      "Ontario NCR",
      "Ontario National Statement",
      "Ontario National Media advisory",
      "Ontario National NCR",
      "Ontario National Statement NCR",
      "Ontario National Speech",
      "Ontario Statement NCR",
      "Ontario Speech",
      "Ontario Media advisory NCR"
    ) ~ "Ontario",
    region %in% c(
      "Manitoba Statement",
      "Saskatchewan National Speech",
      "Saskatchewan National Depot",
      "Saskatchewan Statement Depot",
      "Saskatchewan Media advisory",
      "Saskatchewan Depot",
      "Saskatchewan Media advisory Depot",
      "Saskatchewan National",
      "Saskatchewan National Statement",
      "Maidstone",
      "Shaunavon",
      "Saskatchewan Statement",
      "Archerwill",
      "Lake Diefenbaker",
      "Pelican Narrows",
      "Moose Jaw",
      "Weyburn",
      "Southend",
      "Emma Lake",
      "Biggar",
      "Langenburg"
    ) ~ "Saskatchewan",
    region %in% c(
      "Quebec National Media advisory",
      "Quebec National",
      "Quebec Media advisory"
    ) ~ "Quebec",
    region %in% c(
      "Nova Scotia Media advisory",
      "Nova Scotia National",
      "Halifax Regional Municipality",
      "Nova Scotia Speech",
      "Nova Scotia Statement",
      "Nova Scotia National Speech",
      "Queens and Kings Counties",
      "Victoria County",
      "Digby County",
      "Hants County",
      "Kings County",
      "Kings and Prince Counties",
      "Annapolis County",
      "Colchester County",
      "Antigonish County",
      "Queens and King counties",
      "Inverness County",
      "Queens County",
      "Lunenburg County",
      "Yarmouth County",
      "Antigonish County",
      "Hanty County",
      "Cumberland County",
      "Shelburne County",
      "Richmond County",
      "Green Creek",
      "Coichester County",
      "Richmond Co.",
      "Guysborough County",
      "Pictou County",
      "Annapolis COunty",
      "Annapolis Valley",
      "Hants Co."
    ) ~ "Nova Scotia",
    region %in% c(
      "Manitoba Statement",
      "Manitoba National",
      "Manitoba ",
      "Manitoba Media advisory",
      "Rosebank"
    ) ~ "Manitoba",
    region %in% c(
      "PEI",
      "Queens and Kings Districts",
      "Queens and Kings counties",
      "Queens and Kings County"
    ) ~ "Prince Edward Island",
    region %in% c(
      "N.B. ",
      "N.B.",
      "New Brunswick Statement",
      "Aroostook and Oxbow",
      "New Brunswick Media advisory",
      "NB"
    ) ~ "New Brunswick",
    region %in% c(
      "Yukon Media advisory",
      "Carcross",
      "Yukon ",
      "Whitehorse",
      "Yukon Statement",
      "Ross River",
      "Haines Junction",
      "Faro"
    ) ~ "Yukon",
    region %in% c(
      "Alberta Statement",
      "Alberta National",
      "Alberta Media advisory",
      "Alta.",
      "Alta",
      "Alberta Depot",
      "Alberta National Depot",
      "Alberta National Statement",
      "Three Hills and Stettler"
    ) ~ "Alberta",
    region %in% c(
      "Newfoundland and Labrador Media advisory",
      "Newfoundland and Labrador Statement",
      "Nain",
      "Stephenville",
      "Deer Lake",
      "Hopedale",
      "Ferryland and Stephenville",
      "Grand Falls-Windsor",
      "Holyrood and Stephenville"
    ) ~ "Newfoundland and Labrador",
    region %in% c(
      "British Columbia National",
      "Green Lake"
    ) ~ "British Columbia",
    region %in% c(
      "Nunavut Media advisory"
    ) ~ "Nunavut",
    region %in% c(
      "Northwest Territories Media advisory"
    ) ~ "Northwest Territories",
    TRUE ~ region
  )
}
```

Next we will apply our cleaning function to to our DataFrame, using the `mutate()` function from library(dplyr). Before this, to deal with the 24 *NA* values we identified in **region2**, we are going to apply another dplyr function called `coalesce()`, which will move replace the *NA* values in region2 with the values from **region1**. We also going to add one additional step before applying our custom cleaning function. This will be to trim any unnecessary white space from the beginning and end of each entry in **region2**. To do this, we use the `str_trim()` function from library(stringr). Finally, we'll apply our cleaning function, after which we'll inspect the results to see if it worked.

```{r}
#install.packages("stringr")
library(stringr)

rcmp_news_pp <- rcmp_news_pp %>%
  mutate(region2 = coalesce(region2, region1)) %>%
  mutate(region2 = str_trim(region2)) %>%
  mutate(prov_terr = recode_regions(region2))

paged_table(head(rcmp_news_pp, n = 200))
```


```{r, eval=FALSE}
library(dplyr)
library(ggplot2)
library(stringr)
library(ggridges)
library(hrbrthemes)
```


```{r, eval=FALSE}
p1 <- rcmp_news %>%
  group_by(prov_terr) %>%
  count(name = "count") %>%
  ggplot(aes(x = reorder(prov_terr, count), y = count)) +
  geom_col(fill = "#ca1928", show.legend = FALSE) +
  theme_ipsum(grid="") +
  theme(axis.text.x = element_blank()) +
  geom_text(aes(label=scales::comma(count)), hjust=0, nudge_y=50) +
  expand_limits(y = c(0, 3400)) +
  coord_flip() +
  labs(x = "", y = "")

p1
```

```{r, eval=FALSE}
rcmp_news_count <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(date_published)) %>%
  group_by(prov_terr, date_published) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published))) %>%
  count(name = "count", .drop = TRUE)

rcmp_news_count <- rcmp_news_count %>%
  mutate(date_published = format(date_published, "%Y-%m")) %>%
  mutate(date_published = paste(date_published, "-01", sep = "")) %>%
  mutate(date_published = as.Date(date_published, "%Y-%m-%d"))

rcmp_news_count <- rcmp_news_count %>%
  group_by(date_published, prov_terr) %>%
  summarize(count = sum(count)) %>%
  mutate(total = sum(count)) %>%
  mutate(prop = count/total) %>%
  filter(date_published != "2016-12-01")

p2 <- rcmp_news_count %>%
  ggplot(aes(x = date_published, y = prop, fill = prov_terr)) +
  geom_col(position = "stack") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_date(breaks = as.Date(c("2017-01-01", "2018-01-01", "2019-01-01", "2020-01-01")), date_labels = "%Y") +
  fishualize::scale_fill_fish_d() +
  theme_ipsum(grid = "") +
  labs(y = "Proportion", x = "",
       fill = "")

p2
```

```{r, eval=FALSE}
p3 <- rcmp_news_count %>%
  ggplot(aes(x = date_published, y = count, color = prov_terr)) +
  geom_smooth(se = FALSE) +
  scale_y_continuous() +
  scale_x_date(breaks = as.Date(c("2017-01-01", "2018-01-01", "2019-01-01", "2020-01-01")), date_labels = "%Y") +
  fishualize::scale_color_fish_d() +
  theme_ipsum(grid = "") +
  labs(y = "Number of news releases", x = "",
       color = "")

p3
```

```{r, eval=FALSE}
p4 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  mutate(word_count = str_count(full_text, "\\w+")) %>%
  mutate(word_count_mean = mean(word_count, na.rm = TRUE)) %>%
  group_by(prov_terr) %>%
  ggplot(aes(x = word_count, y = prov_terr)) +
  geom_density_ridges(fill = "#ca1928", show.legend = FALSE) +
  geom_vline(aes(xintercept = word_count_mean), linetype="dotted", size = 1) +
  scale_x_log10(breaks = c(1, 10, 100, 1000, 5805)) +
  theme_ipsum(grid = "X") +
  labs(x = "word count (log scale)", y = "")

p4
```

```{r, eval=FALSE, fig.width=13, fig.height=8}
library(cowplot)

plot_grid(labels = "AUTO", p1, p2, p3, p4)
```

# Sampling and Outputting

```{r, eval=FALSE}
library(gt)
library(paletteer)
library(tidyr)
```

```{r, eval=FALSE}
my_pattern <- "drug|contraband|bath salts|benzodiazepine|methamphetamine|ghb|cocaine|crack|cannabis|marijuana|weed|pot|hash|hashish|lsd| mdma|ecstasy|fentanyl|opioid|pcp|angel dust|acid|salvia|mushroom|heroin|ketamine"
```

```{r, eval=FALSE}
table1 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url),
         !is.na(full_text)) %>%
  group_by(prov_terr, image_url) %>%
  mutate(full_text = str_to_lower(full_text)) %>%
  count(tf = str_detect(full_text, my_pattern)) %>%
  group_by(prov_terr, tf) %>%
  summarize(sum = sum(n)) %>%
  pivot_wider(names_from = tf, values_from = sum) %>%
  mutate(`FALSE` = `FALSE` + `TRUE`) %>%
  rename(`Total NRs w/ Images 2` = `TRUE`,
         `Total NRs 2` = `FALSE`,
         `Province/Territory` = prov_terr) %>%
  mutate(`Percent NRs w/ Images 2` = round(`Total NRs w/ Images 2`/`Total NRs 2`*100, 2)) %>%
  ungroup()

table2 <- rcmp_news %>%
  filter(prov_terr != "British Columbia") %>%
  group_by(prov_terr) %>%
  add_count(prov_terr, name = "total_press_releases") %>%
  add_count(image_url, name = "total_images") %>%
  summarize(total_press_releases = max(total_press_releases),
            total_images = max(total_images)) %>%
  mutate(proportion = round(total_images/total_press_releases*100, 2)) %>%
  select(prov_terr, total_press_releases, total_images, proportion) %>%
  #arrange(desc(total_images)) %>%
  rename(`Province/Territory` = prov_terr,
         `Total NRs` = total_press_releases,
         `Total NRs w/ Images` = total_images,
         `Percent NRs w/ Images` = proportion) %>%
  ungroup()

table3 <- table2 %>%
  left_join(table1, by = c("Province/Territory" = "Province/Territory")) %>%
  rename(` ` = "Province/Territory")

table3 %>%
  gt() %>%
  tab_spanner(label = "Whole Corpus",
              columns = c(`Total NRs`, `Total NRs w/ Images`, `Percent NRs w/ Images`)) %>%
  tab_spanner(label = "Subset Corpus",
              columns = c(`Total NRs 2`, `Total NRs w/ Images 2`, `Percent NRs w/ Images 2`)) %>%
  data_color(
    columns = c(`Total NRs`, `Total NRs w/ Images`, `Percent NRs w/ Images`, `Total NRs 2`, `Total NRs w/ Images 2`, `Percent NRs w/ Images 2`),
    colors = scales::col_numeric(
      paletteer::paletteer_d(
        palette = "ggsci::red_material")
        %>% as.character(),
      domain = NULL
      )
  )
```

```{r, eval=FALSE}
image_meta_data <- rcmp_news %>% 
  ungroup() %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url)) %>%
  mutate(full_text = str_to_lower(full_text)) %>%
  filter(str_detect(full_text, my_pattern)) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published)))

image_urls <- image_meta_data %>% select(image_url)

image_urls1 <- slice(image_urls, 1:250)
image_meta_data1 <- slice(image_meta_data, 1:250)

image_urls2 <- slice(image_urls, 251:500)
image_meta_data2 <- slice(image_meta_data, 251:500)

image_urls3 <- slice(image_urls, 501:750)
image_meta_data3 <- slice(image_meta_data, 501:750)

image_urls4 <- slice(image_urls, 751:997)
image_meta_data4 <- slice(image_meta_data, 751:997)
```

```{r, eval=FALSE}
options(timeout=500)

for (i in image_urls1){
  
  numbers <- 1:250
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data1$prov_terr, "_RCMP_", image_meta_data1$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls2){
  
  numbers <- 251:500
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data2$prov_terr, "_RCMP_", image_meta_data2$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls3){
  
  numbers <- 501:750
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data3$prov_terr, "_RCMP_", image_meta_data3$date_published, "_", numbers, ".jpg", sep = ""))
  
}

for (i in image_urls4){
  
  numbers <- 751:997
  
  download.file(i, paste("/Volumes/ajl_external/rcmp-news-images/rcmp-drug-crimes-corpus/", image_meta_data4$prov_terr, "_RCMP_", image_meta_data4$date_published, "_", numbers, ".jpg", sep = ""))
}
```

```{r, eval=FALSE}
subset_corpus <- rcmp_news %>% 
  ungroup() %>%
  filter(prov_terr != "British Columbia") %>%
  filter(!is.na(image_url)) %>%
  mutate(full_text_lower = str_to_lower(full_text)) %>%
  filter(str_detect(full_text_lower, my_pattern)) %>%
  select(-full_text_lower, -region2) %>%
  mutate(date_published = str_remove_all(pattern= " (\\d{2})(\\:)(\\d{2})(\\:)(\\d{2})", date_published)) %>%
  mutate(date_published = as.Date(lubridate::ymd(date_published))) %>%
  mutate(doc_id = row_number())

subset_corpus <- subset_corpus %>%
  mutate(date_published2 = paste("\n\nDATE: ", as.character(date_published), "\n\n", sep = "")) %>%
  mutate(headline_text = paste("HEADLINE: ", headline_text, "\n\n", sep = "")) %>%
  mutate(headline_url = paste("ARTICLE URL: ", headline_url, "\n\n", sep = "")) %>%
  mutate(image_url = paste("IMAGE URL: ", image_url, "\n\n", sep = "")) %>%
  mutate(prov_terr2 = paste("CITY/TOWN, PROVINCE/TERRITORY: ", region1, prov_terr, "\n\n", sep = "")) %>%
  mutate(full_text = paste("FULL TEXT: ", full_text, "\n\n", sep = "")) %>%
  mutate(text = paste(date_published2, headline_text, headline_url, image_url, prov_terr2, full_text)) %>%
  mutate(doc_names = paste(prov_terr, "_RCMP_", date_published, "_", doc_id, sep = ""))

subset_corpus %>%
  select(doc_names, text) %>%
  group_by(doc_names) %>%
  do(write_csv(., paste0(unique(.$doc_names), ".txt", sep = ""), col_names = FALSE))
```

# Analyzing

# Findings, Discussion, and Conclusion